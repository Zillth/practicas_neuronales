{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Multicapa\n",
    "\n",
    "Una red neuronal multicapa tiene capas ocultas entre la entrada y la salida. A este tipo de red también se le conoce como perceptrón multicapa (MLP por sus siglas en inglés de multilayer perceptron)\n",
    "\n",
    "En este ejercicio crearemos una red neuronal multicapa usando numpy.\n",
    "\n",
    "INSTRUCCIONES: Completa el código faltante.\n",
    "\n",
    "@juan1rving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos paquetes\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones necesarias\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Función sigmoide\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definamos la arquitectura de la red\n",
    "\n",
    "<img src=\"files/test1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Especifica el tamaño de las capas de acuerdo al diagrama.\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_out = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir los pesos\n",
    "\n",
    "Recordemos que los pesos ahora los representamos con matrices y utilizaremos el producton de la siguiente forma:\n",
    "\n",
    "$$\n",
    "h = XW\n",
    "$$\n",
    "\n",
    "tal que,\n",
    "\n",
    "\n",
    "$$W = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2}\n",
    " \\\\\n",
    "w_{2,1} & w_{2,2}\n",
    " \\\\\n",
    "w_{3,1} & w_{3,2}\n",
    " \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "donde los renglones se relacionan con las entradas y las columnas con los nodos intermedios. Y las entradas son\n",
    "\n",
    "$$ X = \\begin{bmatrix} x_1 & x_2 & x_3 \\end{bmatrix} $$\n",
    "\n",
    "Como herramienta usaremos la fucnión normal. Verifica la documentación oficial de la función.\n",
    "\n",
    "> numpy.random.normal(loc=0.0, scale=1.0, size=None)\n",
    "\n",
    "TODO: construye a contrinuación matrices con valores aleatorios para la matriz de pesos entre la entrada y la oculta y para la oculta y la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesos de la capa de entrada a la hidden\n",
      " [[ 0.32408397 -0.38508228 -0.676922  ]\n",
      " [ 0.61167629  1.03099952  0.93128012]\n",
      " [-0.83921752 -0.30921238  0.33126343]\n",
      " [ 0.97554513 -0.47917424 -0.18565898]]\n",
      "pesos de la capa hidden a la salida\n",
      " [[-1.10633497 -1.19620662]\n",
      " [ 0.81252582  1.35624003]\n",
      " [-0.07201012  1.0035329 ]]\n",
      "inputs\n",
      " [[ 0.36163603 -0.64511975  0.36139561  1.53803657]]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Completa el código faltante\n",
    "\n",
    "# Especifica la media y desviación estandar a usar.\n",
    "mean = 0\n",
    "stdev = 1\n",
    "\n",
    "# crea las matrices de forma dinámica a partir de los valores que se pone en los tamaños de la red\n",
    "W_input_to_hidden = np.random.normal(mean, stdev, (N_input, N_hidden))\n",
    "\n",
    "W_hidden_out = np.random.normal(mean, stdev, (N_hidden, N_out))\n",
    "\n",
    "X = np.random.normal(mean, stdev, (1, N_input))\n",
    "\n",
    "print(\"pesos de la capa de entrada a la hidden\\n\", W_input_to_hidden)\n",
    "print(\"pesos de la capa hidden a la salida\\n\", W_hidden_out)\n",
    "print(\"inputs\\n\", X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la salida\n",
    "\n",
    "Recordemos de la lección que\n",
    "\n",
    "$$ h = X W $$\n",
    "\n",
    "$$ y = f(H) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salida de la capa oculta:  [[0.7149872  0.16068863 0.2667021 ]]\n",
      "salida de la red:  [[0.33633788 0.40861454]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Producto punto\n",
    "input_to_hidden = np.dot(X, W_input_to_hidden)\n",
    "out_of_hidden = sigmoid(input_to_hidden)\n",
    "\n",
    "print(\"salida de la capa oculta: \", out_of_hidden)\n",
    "\n",
    "# TODO: Producto punto\n",
    "input_to_out = np.dot(out_of_hidden, W_hidden_out) \n",
    "out_of_network = sigmoid(input_to_out)\n",
    "\n",
    "print(\"salida de la red: \", out_of_network)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado debes de ver la salida de la red como un vector de dos elementos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
